{
  "results": {
    "boolq": {
      "alias": "boolq",
      "acc,none": 0.6513761467889908,
      "acc_stderr,none": 0.008334643232728133
    },
    "hellaswag": {
      "alias": "hellaswag",
      "acc,none": 0.5094602668791077,
      "acc_stderr,none": 0.00498888819406327,
      "acc_norm,none": 0.6786496713802032,
      "acc_norm_stderr,none": 0.00466040556533875
    },
    "mathqa": {
      "alias": "mathqa",
      "acc,none": 0.24757118927973198,
      "acc_stderr,none": 0.007901023441324383,
      "acc_norm,none": 0.24857621440536012,
      "acc_norm_stderr,none": 0.007911755262023768
    },
    "mutual": {
      "alias": "mutual",
      "r@1,none": 0.22573363431151242,
      "r@1_stderr,none": 0.014053085820407459,
      "r@2,none": 0.4401805869074492,
      "r@2_stderr,none": 0.016686597274671547,
      "mrr,none": 0.6691121143717079,
      "mrr_stderr,none": 0.010338800752647375
    },
    "piqa": {
      "alias": "piqa",
      "acc,none": 0.7535364526659413,
      "acc_stderr,none": 0.010054810789671818,
      "acc_norm,none": 0.7709466811751904,
      "acc_norm_stderr,none": 0.009804509865175504
    },
    "winogrande": {
      "alias": "winogrande",
      "acc,none": 0.6448303078137332,
      "acc_stderr,none": 0.013450047479569257
    }
  },
  "group_subtasks": {
    "boolq": [],
    "hellaswag": [],
    "mathqa": [],
    "mutual": [],
    "piqa": [],
    "winogrande": []
  },
  "configs": {
    "boolq": {
      "task": "boolq",
      "tag": [
        "super-glue-lm-eval-v1"
      ],
      "dataset_path": "super_glue",
      "dataset_name": "boolq",
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "{{passage}}\nQuestion: {{question}}?\nAnswer:",
      "doc_to_target": "label",
      "unsafe_code": false,
      "doc_to_choice": [
        "no",
        "yes"
      ],
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc"
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "passage",
      "metadata": {
        "version": 2.0
      }
    },
    "hellaswag": {
      "task": "hellaswag",
      "tag": [
        "multiple_choice"
      ],
      "dataset_path": "hellaswag",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "def process_docs(dataset: datasets.Dataset) -> datasets.Dataset:\n    def _process_doc(doc):\n        ctx = doc[\"ctx_a\"] + \" \" + doc[\"ctx_b\"].capitalize()\n        out_doc = {\n            \"query\": preprocess(doc[\"activity_label\"] + \": \" + ctx),\n            \"choices\": [preprocess(ending) for ending in doc[\"endings\"]],\n            \"gold\": int(doc[\"label\"]),\n        }\n        return out_doc\n\n    return dataset.map(_process_doc)\n",
      "doc_to_text": "{{query}}",
      "doc_to_target": "{{label}}",
      "unsafe_code": false,
      "doc_to_choice": "choices",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": false,
      "metadata": {
        "version": 1.0
      }
    },
    "mathqa": {
      "task": "mathqa",
      "tag": [
        "math_word_problems"
      ],
      "dataset_path": "math_qa",
      "training_split": "train",
      "validation_split": "validation",
      "test_split": "test",
      "doc_to_text": "Question: {{Problem}}\nAnswer:",
      "doc_to_target": "{{['a', 'b', 'c', 'd', 'e'].index(correct)}}",
      "unsafe_code": false,
      "doc_to_choice": "def doc_to_choice(doc):\n    choices = [\n        c[4:].rstrip(\" ,\")\n        for c in re.findall(r\"[abcd] \\) .*?, |e \\) .*?$\", doc[\"options\"])\n    ]\n    return choices\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "Question: {{Problem}}\nAnswer:",
      "metadata": {
        "version": 1.0
      }
    },
    "mutual": {
      "task": "mutual",
      "dataset_path": "EleutherAI/mutual",
      "dataset_name": "mutual",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "training_split": "train",
      "validation_split": "validation",
      "process_docs": "def process_docs(dataset):\n    def _detokenize(text):\n        text = text.replace(\" '\", \"'\")\n        text = text.replace(\" \\n\", \"\\n\")\n        text = text.replace(\"\\n \", \"\\n\")\n        text = text.replace(\" n't\", \"n't\")\n        text = text.replace(\"`` \", '\"')\n        text = text.replace(\"''\", '\"')\n        # punctuation\n        text = text.replace(\" :\", \":\")\n        text = text.replace(\" ;\", \";\")\n        text = text.replace(\" !\", \"!\")\n        text = text.replace(\" ?\", \"?\")\n        text = text.replace(\" ,\", \",\")\n        text = text.replace(\" .\", \".\")\n        return text\n\n    def _process(doc):\n        return {\n            \"article\": _detokenize(doc[\"article\"]),\n            \"options\": [_detokenize(option) for option in doc[\"options\"]],\n        }\n\n    return dataset.map(_process)\n",
      "doc_to_text": "{{article}}",
      "doc_to_target": "{{['A', 'B', 'C', 'D'].index(answers)}}",
      "unsafe_code": false,
      "doc_to_choice": "{{options}}",
      "process_results": "def process_results(doc, results):\n    gold = [\"A\", \"B\", \"C\", \"D\"].index(doc[\"answers\"])\n    r4_1 = np.argmax(results) == gold  # r4_1 = accuracy\n    ranks = sorted(results, reverse=True)\n    r4_2 = (ranks.index(results[gold]) == 1) + r4_1\n    mrr = 1.0 / (ranks.index(results[gold]) + 1)  # `+ 1` for index offset\n    return {\"r@1\": r4_1, \"r@2\": r4_2, \"mrr\": mrr}\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "r@1",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "r@2",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "mrr",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "{{article}}",
      "metadata": {
        "version": 2.0
      }
    },
    "piqa": {
      "task": "piqa",
      "dataset_path": "piqa",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "Question: {{goal}}\nAnswer:",
      "doc_to_target": "label",
      "unsafe_code": false,
      "doc_to_choice": "{{[sol1, sol2]}}",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        },
        {
          "metric": "acc_norm",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "goal",
      "metadata": {
        "version": 1.0
      }
    },
    "winogrande": {
      "task": "winogrande",
      "dataset_path": "winogrande",
      "dataset_name": "winogrande_xl",
      "dataset_kwargs": {
        "trust_remote_code": true
      },
      "training_split": "train",
      "validation_split": "validation",
      "doc_to_text": "def doc_to_text(doc):\n    answer_to_num = {\"1\": 0, \"2\": 1}\n    return answer_to_num[doc[\"answer\"]]\n",
      "doc_to_target": "def doc_to_target(doc):\n    idx = doc[\"sentence\"].index(\"_\") + 1\n    return doc[\"sentence\"][idx:].strip()\n",
      "unsafe_code": false,
      "doc_to_choice": "def doc_to_choice(doc):\n    idx = doc[\"sentence\"].index(\"_\")\n    options = [doc[\"option1\"], doc[\"option2\"]]\n    return [doc[\"sentence\"][:idx] + opt for opt in options]\n",
      "description": "",
      "target_delimiter": " ",
      "fewshot_delimiter": "\n\n",
      "num_fewshot": 0,
      "metric_list": [
        {
          "metric": "acc",
          "aggregation": "mean",
          "higher_is_better": true
        }
      ],
      "output_type": "multiple_choice",
      "repeats": 1,
      "should_decontaminate": true,
      "doc_to_decontamination_query": "sentence",
      "metadata": {
        "version": 1.0
      }
    }
  },
  "versions": {
    "boolq": 2.0,
    "hellaswag": 1.0,
    "mathqa": 1.0,
    "mutual": 2.0,
    "piqa": 1.0,
    "winogrande": 1.0
  },
  "n-shot": {
    "boolq": 0,
    "hellaswag": 0,
    "mathqa": 0,
    "mutual": 0,
    "piqa": 0,
    "winogrande": 0
  },
  "higher_is_better": {
    "boolq": {
      "acc": true
    },
    "hellaswag": {
      "acc": true,
      "acc_norm": true
    },
    "mathqa": {
      "acc": true,
      "acc_norm": true
    },
    "mutual": {
      "r@1": true,
      "r@2": true,
      "mrr": true
    },
    "piqa": {
      "acc": true,
      "acc_norm": true
    },
    "winogrande": {
      "acc": true
    }
  },
  "n-samples": {
    "winogrande": {
      "original": 1267,
      "effective": 1267
    },
    "piqa": {
      "original": 1838,
      "effective": 1838
    },
    "mutual": {
      "original": 886,
      "effective": 886
    },
    "mathqa": {
      "original": 2985,
      "effective": 2985
    },
    "hellaswag": {
      "original": 10042,
      "effective": 10042
    },
    "boolq": {
      "original": 3270,
      "effective": 3270
    }
  },
  "config": {
    "model": "hf",
    "model_args": "pretrained=llm-stacking/StackLLM_7B_300BToken,trust_remote_code=True",
    "model_num_parameters": 5933109248,
    "model_dtype": "torch.bfloat16",
    "model_revision": "main",
    "model_sha": "1dffaf0e8b023be315beba18fd75cf1d63434af9",
    "batch_size": "8",
    "batch_sizes": [],
    "device": null,
    "use_cache": null,
    "limit": null,
    "bootstrap_iters": 100000,
    "gen_kwargs": null,
    "random_seed": 0,
    "numpy_seed": 1234,
    "torch_seed": 1234,
    "fewshot_seed": 1234
  },
  "git_hash": "3914f75",
  "date": 1740743998.1109226,
  "pretty_env_info": "PyTorch version: 2.5.1\nIs debug build: False\nCUDA used to build PyTorch: 12.1\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 22.04.5 LTS (x86_64)\nGCC version: (Anaconda gcc) 11.2.0\nClang version: Could not collect\nCMake version: version 3.22.1\nLibc version: glibc-2.35\n\nPython version: 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0] (64-bit runtime)\nPython platform: Linux-5.15.0-1071-nvidia-x86_64-with-glibc2.35\nIs CUDA available: True\nCUDA runtime version: 11.7.64\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: \nGPU 0: NVIDIA A100-SXM4-40GB\nGPU 1: NVIDIA A100-SXM4-40GB\n\nNvidia driver version: 535.230.02\ncuDNN version: Could not collect\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                         x86_64\nCPU op-mode(s):                       32-bit, 64-bit\nAddress sizes:                        43 bits physical, 48 bits virtual\nByte Order:                           Little Endian\nCPU(s):                               256\nOn-line CPU(s) list:                  0-255\nVendor ID:                            AuthenticAMD\nModel name:                           AMD EPYC 7742 64-Core Processor\nCPU family:                           23\nModel:                                49\nThread(s) per core:                   2\nCore(s) per socket:                   64\nSocket(s):                            2\nStepping:                             0\nFrequency boost:                      enabled\nCPU max MHz:                          2250.0000\nCPU min MHz:                          1500.0000\nBogoMIPS:                             4491.44\nFlags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold avic v_vmsave_vmload vgif v_spec_ctrl umip rdpid overflow_recov succor smca sme sev sev_es\nVirtualization:                       AMD-V\nL1d cache:                            4 MiB (128 instances)\nL1i cache:                            4 MiB (128 instances)\nL2 cache:                             64 MiB (128 instances)\nL3 cache:                             512 MiB (32 instances)\nNUMA node(s):                         8\nNUMA node0 CPU(s):                    0-15,128-143\nNUMA node1 CPU(s):                    16-31,144-159\nNUMA node2 CPU(s):                    32-47,160-175\nNUMA node3 CPU(s):                    48-63,176-191\nNUMA node4 CPU(s):                    64-79,192-207\nNUMA node5 CPU(s):                    80-95,208-223\nNUMA node6 CPU(s):                    96-111,224-239\nNUMA node7 CPU(s):                    112-127,240-255\nVulnerability Gather data sampling:   Not affected\nVulnerability Itlb multihit:          Not affected\nVulnerability L1tf:                   Not affected\nVulnerability Mds:                    Not affected\nVulnerability Meltdown:               Not affected\nVulnerability Mmio stale data:        Not affected\nVulnerability Reg file data sampling: Not affected\nVulnerability Retbleed:               Mitigation; untrained return thunk; SMT enabled with STIBP protection\nVulnerability Spec rstack overflow:   Mitigation; safe RET\nVulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl and seccomp\nVulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:             Mitigation; Retpolines; IBPB conditional; STIBP always-on; RSB filling; PBRSB-eIBRS Not affected; BHI Not affected\nVulnerability Srbds:                  Not affected\nVulnerability Tsx async abort:        Not affected\n\nVersions of relevant libraries:\n[pip3] numpy==2.0.1\n[pip3] torch==2.5.1\n[pip3] torchaudio==2.5.1\n[pip3] torchmetrics==1.6.1\n[pip3] torchvision==0.20.1\n[pip3] triton==3.1.0\n[conda] blas                      1.0                         mkl  \n[conda] cudatoolkit-dev           11.7.0               h1de0b5d_6    conda-forge\n[conda] ffmpeg                    4.3                  hf484d3e_0    pytorch\n[conda] libjpeg-turbo             2.0.0                h9bf148f_0    pytorch\n[conda] mkl                       2023.1.0         h213fc3f_46344  \n[conda] mkl-service               2.4.0           py311h5eee18b_2  \n[conda] mkl_fft                   1.3.11          py311h5eee18b_0  \n[conda] mkl_random                1.2.8           py311ha02d727_0  \n[conda] numpy                     1.26.4                   pypi_0    pypi\n[conda] numpy-base                2.0.1           py311hf175353_1  \n[conda] pytorch                   2.5.1           py3.11_cuda12.1_cudnn9.1.0_0    pytorch\n[conda] pytorch-cuda              12.1                 ha16c6d3_6    pytorch\n[conda] pytorch-mutex             1.0                        cuda    pytorch\n[conda] torch                     2.6.0                    pypi_0    pypi\n[conda] torchaudio                2.6.0                    pypi_0    pypi\n[conda] torchmetrics              1.6.1                    pypi_0    pypi\n[conda] torchtriton               3.1.0                     py311    pytorch\n[conda] torchvision               0.21.0                   pypi_0    pypi\n[conda] triton                    3.2.0                    pypi_0    pypi",
  "transformers_version": "4.31.0",
  "upper_git_hash": null,
  "tokenizer_pad_token": [
    "<unk>",
    "0"
  ],
  "tokenizer_eos_token": [
    "</s>",
    "2"
  ],
  "tokenizer_bos_token": [
    "<s>",
    "1"
  ],
  "eot_token_id": 2,
  "max_length": 2048,
  "task_hashes": {},
  "model_source": "hf",
  "model_name": "llm-stacking/StackLLM_7B_300BToken",
  "model_name_sanitized": "llm-stacking__StackLLM_7B_300BToken",
  "system_instruction": null,
  "system_instruction_sha": null,
  "fewshot_as_multiturn": false,
  "chat_template": null,
  "chat_template_sha": null,
  "start_time": 873142.241551923,
  "end_time": 873818.499463824,
  "total_evaluation_time_seconds": "676.2579119009897"
}